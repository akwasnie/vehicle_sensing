{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qIEJJfzbl_9"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/akwasnie/vehicle_sensing/blob/detection_and_distance/object_tracking_and_dist_calculation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xX3kUxdra7Ft"
   },
   "outputs": [],
   "source": [
    "# In Jupyter, you would need to install TF 2 via !pip.\n",
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DV7RDA4r5gEl"
   },
   "outputs": [],
   "source": [
    "!pip install onnxruntime\n",
    "!pip install range-key-dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRHtTnEl5Ae2"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from base64 import b64decode, b64encode\n",
    "\n",
    "import cv2\n",
    "import IPython\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import torch\n",
    "from google.colab import output\n",
    "from google.colab.output import eval_js\n",
    "from google.colab.patches import cv2_imshow\n",
    "from IPython.display import Image, Javascript, clear_output, display\n",
    "from numpy import asarray\n",
    "from PIL import Image as pimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6MNuo7X05RCu"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/akwasnie/CenterNet.git && cd CenterNet && git checkout 8ef87b433529ac8f8bd4f95707f6bc05052c55e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U72ukvG61KoD"
   },
   "outputs": [],
   "source": [
    "sys.path.append('CenterNet')\n",
    "from CenterNet import src\n",
    "from src.lib.utils.image import get_affine_transform\n",
    "from src.lib.models.decode import ctdet_decode\n",
    "from src.lib.utils.post_process import ctdet_post_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4audkP73Odr"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/'\n",
    "MODEL_FILE = os.path.join(DATA_DIR, 'ctdet_ebike.onnx')\n",
    "CLASS_FILE = os.path.join(DATA_DIR, 'ebike.json')\n",
    "IMAGES_ZIP = os.path.join(DATA_DIR, 'distance_images.zip')\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(MODEL_FILE):\n",
    "    !gdown --id 168n5dPHGBoRTpZyZaH6V04AR5w-HYbC_ -O $MODEL_FILE\n",
    "else:\n",
    "    print('Model file ({}) already exists.'.format(MODEL_FILE))\n",
    "\n",
    "if not os.path.exists(CLASS_FILE):\n",
    "    !gdown --id 1qCIeX44a5zBaKpDa6KDz30H9qCULwgP2 -O $CLASS_FILE\n",
    "else:\n",
    "    print('Class file ({}) already exists.'.format(CLASS_FILE))\n",
    "    \n",
    "if not os.path.exists(IMAGES_ZIP):\n",
    "    !gdown --id 1GlaTbuNagGgB-u1gzuJu3ANJ7kfzWeX9 -O $IMAGES_ZIP\n",
    "    !unzip $IMAGES_ZIP\n",
    "else:\n",
    "    print('Images zip ({}) already exists.'.format(IMAGES_ZIP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SiK1Iz6G5yig"
   },
   "outputs": [],
   "source": [
    "IN_SIZE = [512,512]\n",
    "MEAN = [0.408, 0.447, 0.470]\n",
    "STD = [0.289, 0.274, 0.278]\n",
    "MAX_BB_NUM = 1\n",
    "THRESHOLD = 0.5\n",
    "size_mapping = {\n",
    "    'car': 200,\n",
    "    'truck': 245,\n",
    "    'bike': 65,\n",
    "    'motorbike': 90,\n",
    "    'bus': 255,\n",
    "  }\n",
    "focal_length_pixels = 890\n",
    "#  <5m; <10m; <20m; <30m; <40m; <50m; <75m; <100m; <125m; <150m; <200m; <300m; <500m\n",
    "from range_key_dict import RangeKeyDict\n",
    "range_mapping = RangeKeyDict({\n",
    "                (0, 500) : \"<5m\",\n",
    "                (501, 1000) : \"<10m\",\n",
    "                (1001, 2000) : \"<20m\",\n",
    "                (2001, 3000) : \"<30m\",\n",
    "                (3001, 4000) : \"<40m\",\n",
    "                (4001, 5000) : \"<50m\",\n",
    "                (5001, 7500) : \"<75m\",\n",
    "                (7501, 10000) : \"<100m\",\n",
    "                (10001, 12500) : \"<125m\",\n",
    "                (12501, 15000) : \"<150m\",\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFdHZx5h4ARR"
   },
   "outputs": [],
   "source": [
    "def preprocess(image_path):\n",
    "  image = cv2.imread(image_path)\n",
    "  frame = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  h, w = frame.shape[:2]\n",
    "  c = [np.array([w/2., h/2.], dtype=np.float32)]\n",
    "  s = [max(h, w) * 1.0]\n",
    "  trans_input = get_affine_transform(c[0], s[0], 0, IN_SIZE)\n",
    "  im_data = cv2.warpAffine(\n",
    "      frame, trans_input,\n",
    "      (IN_SIZE[0], IN_SIZE[1]),\n",
    "      flags=cv2.INTER_LINEAR,\n",
    "  )\n",
    "  im_data = ((im_data / 255. - MEAN) / STD).astype(np.float32)\n",
    "  im_data = im_data.transpose(2, 0, 1).reshape(1, 3, IN_SIZE[0], IN_SIZE[1])\n",
    "  return frame, im_data, c, s\n",
    "\n",
    "def import_data(model_path, class_mapping_path):\n",
    "  ort_session = onnxruntime.InferenceSession(model_path)\n",
    "\n",
    "  with open(class_mapping_path, 'r') as fp:\n",
    "    category_index = json.load(fp)\n",
    "  return ort_session, category_index\n",
    "\n",
    "def centernet2cocodict(out, c, m, category_index):\n",
    "    hm = torch.from_numpy(out[0])\n",
    "    wh = torch.from_numpy(out[1])\n",
    "    reg = torch.from_numpy(out[2])\n",
    "    hm = hm.sigmoid_()\n",
    "    dets = ctdet_decode(hm, wh, reg=reg, cat_spec_wh=False, K=MAX_BB_NUM)\n",
    "    dets = dets.detach().cpu().numpy()\n",
    "    dets = ctdet_post_process(dets.copy(), c, m, 128, 128, 80)[0]\n",
    "\n",
    "    results = {}  \n",
    "    for j in range(1, 5 + 1):\n",
    "        results[j] = np.array(dets[j], dtype=np.float32).reshape(-1, 5)\n",
    "    \n",
    "    scores = np.hstack([results[j][:, 4] for j in range(1, 5 + 1)])\n",
    "\n",
    "    out_dict = {\n",
    "        'num_detections': MAX_BB_NUM,\n",
    "        'detection_boxes': [],\n",
    "        'detection_scores': [],\n",
    "        'detection_classes': [],\n",
    "        }\n",
    "\n",
    "    cats = list(category_index.values())\n",
    "    cats.sort(key=lambda x: x['id'])\n",
    "\n",
    "    for j in range(1, 5 + 1):\n",
    "        for bbox in results[j]:\n",
    "            if bbox[4] > THRESHOLD:\n",
    "                out_dict['detection_boxes'].append(bbox[:4])\n",
    "                out_dict['detection_scores'].append(bbox[4])\n",
    "                out_dict['detection_classes'].append(cats[j]['id'])\n",
    "\n",
    "    out_dict['detection_boxes'] = np.asarray(out_dict['detection_boxes'])\n",
    "    out_dict['detection_scores'] = np.asarray(out_dict['detection_scores'])\n",
    "    out_dict['detection_classes'] = np.asarray(out_dict['detection_classes'])\n",
    "\n",
    "    return out_dict\n",
    "\n",
    "def run_inference(ort_session, category_index, image_data, c, s):\n",
    "  output = ort_session.run(None, {ort_session.get_inputs()[0].name: image_data})\n",
    "  output_dict = centernet2cocodict(output, c, s, category_index)\n",
    "  return output_dict\n",
    "\n",
    "def calculate_distance(delta_x_pixels, class_name):\n",
    "  distance = size_mapping[class_name] * focal_length_pixels/delta_x_pixels\n",
    "  return range_mapping[int(distance)]\n",
    "\n",
    "def draw_text(img, text,\n",
    "          pos=(0, 0),\n",
    "          font=cv2.FONT_HERSHEY_PLAIN,\n",
    "          font_scale=5,\n",
    "          font_thickness=2,\n",
    "          text_color=(255, 0, 0),\n",
    "          text_color_bg=(255, 255, 255, 0.5)\n",
    "          ):\n",
    "\n",
    "    x, y = pos\n",
    "    text_size, _ = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "    text_w, text_h = text_size\n",
    "    cv2.rectangle(img, (x-5, y-5), (x + text_w+5, y + text_h+5), text_color_bg, -1)\n",
    "    cv2.putText(img, text, (x, y + text_h + font_scale - 1), font, font_scale, text_color, font_thickness)\n",
    "\n",
    "    return text_size\n",
    "\n",
    "ort_session, category_index = import_data(MODEL_FILE, CLASS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIUg1hfC957b"
   },
   "outputs": [],
   "source": [
    "FILENAME = \"distance_images/10_f.JPG\"\n",
    "frame, image_data, c, s = preprocess(FILENAME)\n",
    "ort_session, category_index = import_data(MODEL_FILE, CLASS_FILE)\n",
    "output_dict = run_inference(ort_session, category_index, image_data, c, s)\n",
    "print(output_dict)\n",
    "for i in range(len(output_dict['detection_boxes'])):\n",
    "  bbox = output_dict['detection_boxes'][i]\n",
    "  class_name = category_index[str(output_dict['detection_classes'][i])]['name']\n",
    "  distance = calculate_distance(abs(int(bbox[2])-int(bbox[0])), class_name)\n",
    "   # if width is greater than height, ignore - side view\n",
    "  if (abs(int(bbox[2])-int(bbox[0]))>abs(int(bbox[3])-int(bbox[1]))):\n",
    "    distance = \"\"\n",
    "  print(distance)\n",
    "  cv2.rectangle(frame,\n",
    "                (int(bbox[0]), int(bbox[1])),\n",
    "                (int(bbox[2]), int(bbox[3])),\n",
    "                (255,0,0),\n",
    "                2)\n",
    "  draw_text(frame,\n",
    "            class_name + \" \" + distance,\n",
    "            (int(bbox[0]), int(bbox[1]-20)))\n",
    "result = np.asarray(frame)\n",
    "result = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "cv2_imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EYlTtRCNn0e2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Realtime_object_tracking.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
